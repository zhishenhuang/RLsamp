{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6630bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 88 from PyObject\n",
      "/opt/anaconda/envs/pyenv/lib/python3.9/site-packages/h5py/__init__.py:46: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# import gym\n",
    "from header import *\n",
    "from utils import *\n",
    "from replay_buffer import *\n",
    "from models import poly_net, val_net\n",
    "from reconstructors import sigpy_solver\n",
    "from policies import DQN\n",
    "from importlib import reload\n",
    "memory_len = 10\n",
    "t_backtrack = 3\n",
    "heg = 192\n",
    "wid = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e75914",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/mnt/shared_a/OCMR/OCMR_fully_sampled_images/'\n",
    "ncfiles = list([])\n",
    "for file in os.listdir(datapath):\n",
    "    if file.endswith(\".pt\"):\n",
    "        ncfiles.append(file)\n",
    "loader = ocmrLoader(ncfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "573563ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AC1_trainer():\n",
    "    def __init__(self, dataloader, polynet, valnet,\n",
    "                  fulldim:int=144,base:int=10,budget:int=50,\n",
    "                  gamma:float=.8,\n",
    "                  horizon:int=None,\n",
    "                  max_trajectories:int=100,\n",
    "                  lr:float=.1,\n",
    "                  init_base:int=10,\n",
    "                  L:float=5e-3,\n",
    "                  max_iter:int=100,\n",
    "                  solver:str='ADMM',\n",
    "                  device=torch.device('cpu'),\n",
    "                  save_dir:str='/home/huangz78/rl_samp/'):\n",
    "        self.dataloader = dataloader\n",
    "        self.dataloader.reset()\n",
    "        self.polynet    = polynet\n",
    "        self.valnet     = valnet\n",
    "        self.fulldim    = fulldim\n",
    "        self.base       = int(base)\n",
    "        self.budget     = int(budget)\n",
    "        self.gamma      = gamma\n",
    "        if horizon is None:\n",
    "            self.horizon = self.budget\n",
    "        else:\n",
    "            self.horizon = int(horizon)\n",
    "        self.lr         = lr\n",
    "        self.optimizer_val  = optim.Adam(self.valnet.parameters(),  lr=lr)\n",
    "        self.optimizer_poly = optim.Adam(self.polynet.parameters(), lr=lr)\n",
    "        self.init_base  = int(init_base)\n",
    "        self.max_trajectories = int(max_trajectories)\n",
    "        ## reconstructor parameters\n",
    "        self.L = L\n",
    "        self.max_iter = int(max_iter)\n",
    "        self.solver = 'ADMM'\n",
    "        self.device = device\n",
    "        \n",
    "        self.reward_per_horizon = []\n",
    "        self.save_dir = save_dir\n",
    "    \n",
    "    def get_action(self, curr_obs, mask=None):\n",
    "        '''\n",
    "        here the mask is 1D\n",
    "        '''\n",
    "        if mask is not None:\n",
    "            assert(len(mask.shape)==1)\n",
    "        res  = self.polynet(curr_obs,mask) # Jul 5, add mask here as second input\n",
    "        loc  = torch.argmax(res)\n",
    "        prob = res.gather(dim=1,index=loc.long().view(-1,1)).squeeze()\n",
    "        return loc, prob\n",
    "        \n",
    "    def step(self, action, target_gt, mask):\n",
    "        '''\n",
    "        action: [1] TODO: adding multiple lines at a time\n",
    "        mask:[W]\n",
    "        data:[N1HW]\n",
    "        target:[N1HW]\n",
    "        '''\n",
    "        ### observe target_gt with old freq info\n",
    "        target_obs_freq = fft_observe(target_gt,mask,return_opt='freq',roll=True) # roll=True because using sigpy\n",
    "        img_recon = sigpy_solver(target_obs_freq, \n",
    "                                 L=self.L,max_iter=self.max_iter,solver=self.solver,\n",
    "                                 heg=target_gt.shape[2],wid=target_gt.shape[3])\n",
    "        old_nrmse = NRMSE(img_recon,target_gt)\n",
    "        \n",
    "        ### observe target_gt with new freq info\n",
    "        mask[action] = 1 # incorporate action into mask\n",
    "        target_obs_freq = fft_observe(target_gt,mask,return_opt='freq',roll=True) # roll=True because using sigpy\n",
    "        next_obs  = sigpy_solver(target_obs_freq, \n",
    "                                 L=self.L,max_iter=self.max_iter,solver=self.solver,\n",
    "                                 heg=target_gt.shape[2],wid=target_gt.shape[3])\n",
    "        new_nrmse = NRMSE(next_obs,target_gt)\n",
    "        reward    = old_nrmse - new_nrmse\n",
    "        \n",
    "        return next_obs, reward\n",
    "        \n",
    "    def run(self):\n",
    "        for trajectory in range(self.max_trajectories):\n",
    "            \n",
    "            print(f'trajectory [{trajectory+1}/{self.max_trajectories}]')\n",
    "            mask = mask_naiveRand(self.fulldim,fix=self.base,other=0,roll=False) # curr_state\n",
    "            I = 1\n",
    "            reward_horizon = 0\n",
    "            for t in range(self.horizon):\n",
    "                breakpoint()\n",
    "                data_source, data_target = self.dataloader.load()\n",
    "                curr_obs = fft_observe(data_source, mask)\n",
    "                action, prob = self.get_action(curr_obs, mask=mask)\n",
    "                \n",
    "                next_obs_last_slice, reward = self.step(action, data_target, copy.deepcopy(mask)) \n",
    "                reward_horizon += reward\n",
    "                v = self.valnet(curr_obs)\n",
    "                with torch.no_grad():\n",
    "                    next_obs = torch.concat((curr_obs[:,1:,:,:],next_obs_last_slice),dim=1)\n",
    "                    vnew  = self.valnet(next_obs)\n",
    "                    delta = reward + self.gamma * vnew  - v # should check if delta == 0\n",
    "                self.optimizer_val.zero_grad()\n",
    "                val_loss = - delta * v\n",
    "                val_loss.backward()\n",
    "                self.optimizer_val.step()\n",
    "                \n",
    "                self.optimizer_poly.zero_grad()\n",
    "                poly_loss = - I * delta * torch.log(prob)\n",
    "                poly_loss.backward()\n",
    "                self.optimizer_poly.step()\n",
    "                \n",
    "                I *= self.gamma\n",
    "                mask[action] = 1\n",
    "                print(f'step: {self.steps}, poly_loss: {poly_loss.detach().item():.4f}, val_loss: {val_loss.detach().item():.4f}, reward: {reward.mean().item():.4f}, \\n mask sum: {mask.sum().item()}')\n",
    "                torch.cuda.empty_cache()\n",
    "            self.reward_per_horizon.append(reward_horizon)\n",
    "    \n",
    "    def save(self):\n",
    "        filename = f'AC1_hist.pt'\n",
    "        torch.save(\n",
    "                    {\n",
    "                        \"polynet_weights\": self.polynet.state_dict(),\n",
    "                        \"valnet_weights\": self.valnet.state_dict(),\n",
    "                        \"reward_per_horizon\":self.reward_per_horizon,\n",
    "                    },\n",
    "                    self.save_dir + filename,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14039f5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current file: fs_0019_3T.pt\n",
      "trajectory [1/100]\n",
      "> \u001b[0;32m/tmp/ipykernel_21748/2443126542.py\u001b[0m(85)\u001b[0;36mrun\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     83 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhorizon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     84 \u001b[0;31m                \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 85 \u001b[0;31m                \u001b[0mdata_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     86 \u001b[0;31m                \u001b[0mcurr_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfft_observe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     87 \u001b[0;31m                \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_21748/2443126542.py\u001b[0m(86)\u001b[0;36mrun\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     84 \u001b[0;31m                \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     85 \u001b[0;31m                \u001b[0mdata_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 86 \u001b[0;31m                \u001b[0mcurr_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfft_observe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     87 \u001b[0;31m                \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     88 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_21748/2443126542.py\u001b[0m(87)\u001b[0;36mrun\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     85 \u001b[0;31m                \u001b[0mdata_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     86 \u001b[0;31m                \u001b[0mcurr_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfft_observe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 87 \u001b[0;31m                \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     88 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     89 \u001b[0;31m                \u001b[0mnext_obs_last_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_21748/2443126542.py\u001b[0m(89)\u001b[0;36mrun\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     87 \u001b[0;31m                \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     88 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 89 \u001b[0;31m                \u001b[0mnext_obs_last_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     90 \u001b[0;31m                \u001b[0mreward_horizon\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     91 \u001b[0;31m                \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "TypeError: fft_observe() got an unexpected keyword argument 'roll'\n",
      "> \u001b[0;32m/tmp/ipykernel_21748/2443126542.py\u001b[0m(89)\u001b[0;36mrun\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     87 \u001b[0;31m                \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     88 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 89 \u001b[0;31m                \u001b[0mnext_obs_last_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     90 \u001b[0;31m                \u001b[0mreward_horizon\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     91 \u001b[0;31m                \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21748/3633655387.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mv_net\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mval_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAC1_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolynet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_21748/2443126542.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext_obs_last_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0mreward_horizon\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/pyenv/lib/python3.9/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c_call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/pyenv/lib/python3.9/bdb.py\u001b[0m in \u001b[0;36mdispatch_exception\u001b[0;34m(self, frame, arg)\u001b[0m\n\u001b[1;32m    172\u001b[0m                     and arg[0] is StopIteration and arg[2] is None):\n\u001b[1;32m    173\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# Stop at the StopIteration or GeneratorExit exception when the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# has set stopframe in a generator by issuing a return command, or a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "p_net   = poly_net(samp_dim=wid,softmax=True)\n",
    "v_net   = val_net()\n",
    "trainer = AC1_trainer(loader, polynet=p_net, valnet=v_net)\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32cd5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RL_trainer():\n",
    "    def __init__(self,dataloader,policy,memory,episodes:int=10,eps:float=1e-3,\n",
    "                 fulldim:int=144,base:int=10,budget:int=50,\n",
    "                 save_dir:str='/home/huangz78/rl_samp/'):\n",
    "        self.dataloader = dataloader\n",
    "        self.dataloader.reset()\n",
    "        \n",
    "        self.policy   = policy\n",
    "        self.memory   = memory\n",
    "        self.episodes = episodes\n",
    "        self.epi      = 0\n",
    "        self.fulldim  = fulldim\n",
    "        self.base     = base\n",
    "        self.budget   = budget\n",
    "        self.eps      = eps\n",
    "        self.training_record = {'loss':[],'grad_norm':[],'q_values_mean':[],'q_values_std':[]}\n",
    "        self.steps    = 0\n",
    "        self.save_dir = save_dir\n",
    "    def train(self):      \n",
    "        # run training\n",
    "        while self.epi < self.episodes:\n",
    "            print(f'episode [{self.epi+1}/{self.episodes}]')\n",
    "            mask = mask_naiveRand(self.fulldim,fix=self.base,other=0,roll=False)   \n",
    "            # one mask at a time, start with a low frequency mask\n",
    "            while mask.sum() < self.budget + self.base:\n",
    "                self.steps += 1\n",
    "#                 print(f'step: {self.steps}, beginning, mask sum: {mask.sum().item()}')\n",
    "                data_source, data_target = self.dataloader.load()\n",
    "                mask_RL   = copy.deepcopy(mask)\n",
    "                mask_rand = copy.deepcopy(mask)\n",
    "#                 epsilon = _get_epsilon(steps_epsilon, self.options)\n",
    "                curr_obs = fft_observe(data_source,mask_RL)\n",
    "                action   = self.policy.get_action(curr_obs, mask=mask_RL, eps_threshold=self.eps)\n",
    "                next_obs, reward = self.policy.step(action, data_target, mask_RL)\n",
    "#                 print(f'step: {self.steps}, policy.step, mask_RL sum: {mask_RL.sum().item()}')\n",
    "                \n",
    "                self.memory.push(curr_obs, mask, action, next_obs, reward)\n",
    "                mask = copy.deepcopy(mask_RL)\n",
    "#                 print(f'step: {self.steps}, assign, mask sum: {mask.sum().item()}')\n",
    "                \n",
    "                ### compare with random policy\n",
    "                with torch.no_grad():\n",
    "                    action_rand = self.policy.get_rand_action(mask=mask_rand)\n",
    "                    _, reward_rand = self.policy.step(action_rand, data_target, mask_rand)\n",
    "                ###\n",
    "                \n",
    "                update_results = self.policy.update_parameters()\n",
    "                if update_results is not None:\n",
    "                    for key in self.training_record.keys():\n",
    "                        self.training_record[key].append(update_results[key])\n",
    "                    curr_loss = update_results['loss']\n",
    "                    print(f'step: {self.steps}, loss: {curr_loss:.4f}, RL reward: {reward.mean().item():.4f}, Rand reward: {reward_rand.mean().item():.4f} \\n mask sum: {mask.sum().item()}')\n",
    "                    torch.cuda.empty_cache()\n",
    "                else:\n",
    "                    print(f'step: {self.steps}, burn in, mask sum: {mask.sum().item()}')\n",
    "                \n",
    "                if type(self.policy).__name__.lower() == 'ddqn':\n",
    "                    if self.steps % self.policy.freq_dqn_checkpoint_save == 0:\n",
    "                        self.save()\n",
    "                    if self.steps % self.policy.target_net_update_freq == 0:\n",
    "                        self.target_net.load_state_dict(self.policy.model.state_dict())\n",
    "            self.dataloader.reset()\n",
    "            self.epi += 1\n",
    "    \n",
    "    def save(self):\n",
    "        filename = f'{type(self.policy).__name__}_hist.pt'\n",
    "        if type(self.policy).__name__.lower() == 'ddqn': \n",
    "            torch.save(\n",
    "                    {\n",
    "                        \"dqn_weights\": self.policy.model.state_dict(),\n",
    "                        \"target_weights\": self.policy.target_net.state_dict(),\n",
    "                        \"steps\": self.steps,\n",
    "                        \"training_record\":self.training_record,\n",
    "                    },\n",
    "                    self.save_dir + filename,\n",
    "                )\n",
    "        elif type(self.policy).__name__.lower() == 'dqn':\n",
    "            torch.save(\n",
    "                    {\n",
    "                        \"dqn_weights\": self.policy.model.state_dict(),\n",
    "                        \"steps\": self.steps,\n",
    "                        \"training_record\":self.training_record,\n",
    "                    },\n",
    "                    self.save_dir + filename,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fd2227",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory  = ReplayMemory(capacity=memory_len,\n",
    "                       curr_obs_shape=(t_backtrack,heg,wid),\n",
    "                       mask_shape=(wid),\n",
    "                       next_obs_shape=(1,heg,wid),\n",
    "                       batch_size=2,\n",
    "                       burn_in=2)\n",
    "model   = poly_net(samp_dim=wid)\n",
    "policy  = DQN(model,memory)\n",
    "trainer = RL_trainer(loader,policy,memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f6364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dqn\n",
    "reload(dqn)\n",
    "from dqn import DQN\n",
    "\n",
    "import replay_buffer\n",
    "reload(replay_buffer)\n",
    "from replay_buffer import *\n",
    "\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7715bac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RL_tester():\n",
    "    def __init__(self,dataloader,policy,\n",
    "                 fulldim:int=144,base:int=10,budget:int=50):\n",
    "        self.dataloader = dataloader\n",
    "        self.dataloader.reset()\n",
    "        \n",
    "        self.policy   = policy\n",
    "        self.epi = 0\n",
    "        self.episodes = self.dataloader.files\n",
    "        self.fulldim = fulldim # full size of the dimension to be sampled\n",
    "        self.base = base\n",
    "        self.budget = budget\n",
    "        self.eps = eps\n",
    "        self.test_record = {'loss':[],'grad_norm':[],'q_values_mean':[],'q_values_std':[]}\n",
    "        self.testRec = np.zeros((self.episodes))\n",
    "        self.steps = 0\n",
    "    \n",
    "    def run(self):  \n",
    "        self.policy.model.eval()\n",
    "        # run training\n",
    "        while self.epi < self.episodes:\n",
    "            print(f'file [{self.epi+1}/{self.episodes}]')\n",
    "            mask = mask_naiveRand(self.fulldim,fix=self.base,other=0,roll=False)\n",
    "            epi_loss = 0\n",
    "            slice_count = 0\n",
    "            # one mask at a time, start with a low frequency mask\n",
    "            while mask.sum() < self.budget + self.base:\n",
    "                self.steps += 1\n",
    "                data_source, data_target = self.dataloader.load()\n",
    "#                 epsilon = _get_epsilon(steps_epsilon, self.options)\n",
    "                curr_obs = fft_observe(data_source,mask)\n",
    "                action   = self.policy.get_action(curr_obs, mask=mask, eps_threshold=self.eps)\n",
    "                next_obs, _ = self.policy.step(action, data_target, mask)  \n",
    "                \n",
    "#                 ### compare with random policy\n",
    "#                 with torch.no_grad():\n",
    "#                     action_rand = self.policy.get_rand_action(mask=mask_rand)\n",
    "#                     _, reward_rand = self.policy.step(action_rand, data_target, mask_rand)\n",
    "#                 ###\n",
    "            # \n",
    "            self.dataloader.reset_iter()\n",
    "            self.dataloader.train_mode = False\n",
    "            runFlag = True\n",
    "            while runFlag:\n",
    "                data_source, data_target = self.dataloader.load()\n",
    "                curr_obs  = fft_observe(data_source,mask,return_opt='freq')\n",
    "                img_recon = sigpy_solver(curr_obs, \n",
    "                                 L=self.policy.L,max_iter=self.policy.max_iter,solver=self.policy.solver,\n",
    "                                 heg=curr_obs.shape[2],wid=curr_obs.shape[3])\n",
    "                curr_nrmse = NRMSE(img_recon,data_source)\n",
    "                epi_loss += curr_nrmse * curr_obs.shape[0]\n",
    "                slice_count += curr_obs.shape[0]\n",
    "                if data_source is None:\n",
    "                    runFlag = False\n",
    "            self.testRec[self.epi] = epi_loss / slice_count\n",
    "#                 if self.steps % self.options.target_net_update_freq == 0:\n",
    "#                     self.logger.info(\"Updating target network.\")\n",
    "#                     self.target_net.load_state_dict(self.policy.state_dict())\n",
    "            self.dataloader.reset()\n",
    "            self.epi += 1\n",
    "        return np.mean(self.testRec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
